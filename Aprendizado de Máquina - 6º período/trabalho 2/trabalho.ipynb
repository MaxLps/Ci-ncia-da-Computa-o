{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import zipfile\n",
    "import io\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A função h calcula a hipótese de regressão linear usando o vetor de coeficientes 'theta' e os recursos 'x[i]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x, i, theta):\n",
    "    \n",
    "    h = theta[0]\n",
    "    \n",
    "    for j in range(1, len(theta)):\n",
    "        h += x[i][j-1] * theta[j]\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do algoritmo de gradiente descendente para otimizar os coeficientes 'theta'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALFA = 0.000001\n",
    "\n",
    "eixo_X = []\n",
    "eixo_Y = []\n",
    "\n",
    "def gradiente_descendente(x,y,theta):\n",
    "    #temp = [0] * len(theta)    # Lista temporária para armazenar os novos valores de theta\n",
    "    \n",
    "    m = len(x)              # Número de exemplos de treinamento\n",
    "    n = len(theta)          # Número de coeficientes theta\n",
    "    \n",
    "    #max_diff = 10\n",
    "    ite = 0\n",
    "    while ite < 6000:   # Critério de parada: diferença máxima entre os valores antigos e novos de theta  \n",
    "        eixo_Y.append(ite)\n",
    "        custo = 0\n",
    "        for i in range(m):    # Loop sobre os exemplos de treinamento\n",
    "            hip = h(x, i, theta)    # Calcula a hipótese para o exemplo i\n",
    "            custo += hip - y[i]\n",
    "        \n",
    "        custo = 1/m * custo      \n",
    "        eixo_X.append(abs(custo))\n",
    "\n",
    "        \n",
    "        theta[0] = theta[0] - ALFA * custo  # Atualiza temp[0] usando a taxa de aprendizado\n",
    "        for j in range(1, n):\n",
    "            theta[j] = theta[j] - ALFA * custo * x[i][j-1]   \n",
    "\n",
    "        #max_diff = min(abs(temp[i] - theta[i]) for i in range(len(theta)))\n",
    "    \n",
    "        # for i in range(n):\n",
    "        #     theta[i] = temp[i]  # Atualiza os valores de theta\n",
    "        ite += 1\n",
    "        #print(custo, ite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solucao_analitica(x,y,theta):\n",
    "    m = len(y)\n",
    "    \n",
    "    xt =  x.transpose()\n",
    "    \n",
    "    theta[:] = (2/m) * np.linalg.pinv(xt @ x) @ xt @ y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMSTrainer(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, analitic=False):\n",
    "            \n",
    "        self.analitic = analitic\n",
    "        self._trained = False\n",
    "            \n",
    "    def fit(self, X, theta,y=None):\n",
    "        if self.analitic:\n",
    "            \n",
    "            coluna_um = [1] * len(y)\n",
    "            x2 = np.insert(X, 0, coluna_um, axis=1)\n",
    "            \n",
    "            solucao_analitica(x2,y,theta)\n",
    "            \n",
    "        else:\n",
    "            gradiente_descendente(X,y, theta)\n",
    "        \n",
    "        self._trained = True\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X, theta, y=None):\n",
    "        \n",
    "        if not self._trained:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        \n",
    "        teste = [0] * len(y)\n",
    "        gab = [0] * len(y)\n",
    "        for i in range(len(y)):\n",
    "            teste[i] = int(h(X, i, theta))\n",
    "            gab[i] = y[i]\n",
    "        print(\"Teste:\")\n",
    "        print(teste)\n",
    "        print(\"Gabarito:\")\n",
    "        print(gab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame : https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume\n",
    "# Normalizando DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)  # Mostrar todas as colunas\n",
    "# pd.set_option('display.expand_frame_repr', False)  # Evitar quebras de linha nas linhas\n",
    "# pd.set_option('display.max_rows', None)  # Mostrar todas as linhas (cuidado com DataFrames muito grandes)\n",
    "\n",
    "# df = pd.read_csv('Metro_Interstate_Traffic_Volume.csv')\n",
    "\n",
    "# df['target_column'] = df['traffic_volume']  # Renomeando a coluna alvo\n",
    "# df = df.drop('traffic_volume', axis=1)      # Remocendo a coluna antiga\n",
    " \n",
    "\n",
    "# df = df.fillna(0)                                                   # Coloando 0 nos valores 'None' (dias sem feriado)\n",
    "# df['holiday'] = df['holiday'].apply(lambda x: 1 if x != 0 else 0)   # Colocando 1 na coluna 'feriado' nas linhas que tem feriado\n",
    "\n",
    "# df = pd.get_dummies(df, columns=['weather_main','weather_description']) # Aplicando one-hot encoding às colunas 'weather_main' e 'weather_description' do DataFrame df \n",
    "\n",
    "# df['date_time'] = pd.to_datetime(df['date_time']) # Normalizando a coluna 'date_time' usando o StandardScaler e armazenando os valores normalizados em uma nova coluna 'date_time_normalized'.\n",
    "\n",
    "# # Normalizar a coluna \"date_time\"\n",
    "# scaler = StandardScaler()\n",
    "# df['date_time_normalized'] = scaler.fit_transform(df[['date_time']])\n",
    "# df = df.drop('date_time', axis=1)\n",
    "\n",
    "# df = df.replace({True: 1, False: 0})\n",
    "\n",
    "# print(df)\n",
    "\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# #Ajuste o scaler aos seus dados\n",
    "# scaler.fit(new_data)\n",
    "\n",
    "# #Aplique a transformação de normalização\n",
    "# data_normalized = scaler.transform(new_data)\n",
    "\n",
    "# print(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL direto para o arquivo ZIP\n",
    "url = \"https://archive.ics.uci.edu/static/public/186/wine+quality.zip\"\n",
    "\n",
    "# Baixar o arquivo ZIP\n",
    "response = requests.get(url)\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "# Escolher o arquivo CSV a ser lido (por exemplo, 'winequality-red.csv')\n",
    "file_to_read = 'winequality-red.csv'\n",
    "\n",
    "# Ler o arquivo CSV dentro do ZIP\n",
    "df = pd.read_csv(zip_file.open(file_to_read),sep=\";\")\n",
    "\n",
    "\n",
    "df['target_column'] = df['quality']  # Renomeando a coluna alvo\n",
    "df = df.drop('quality', axis=1)      # Remocendo a coluna antiga \n",
    "\n",
    "#print(df)\n",
    "\n",
    "\n",
    "# df = df.fillna(0)  \n",
    "\n",
    "# df = pd.DataFrame(df)\n",
    "\n",
    "# # Remover linhas com valores NaN\n",
    "# df = df.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df['target_column2'] = df['Zone 2  Power Consumption']  # Renomeando a coluna alvo\n",
    "# df = df.drop('Zone 2  Power Consumption', axis=1)      # Remocendo a coluna antiga \n",
    "\n",
    "\n",
    "# df['target_column3'] = df['Zone 3  Power Consumption']  # Renomeando a coluna alvo\n",
    "# df = df.drop('Zone 3  Power Consumption', axis=1)      # Remocendo a coluna antiga \n",
    "\n",
    "\n",
    "# df['DateTime'] = pd.to_datetime(df['DateTime']) # Normalizando a coluna 'date_time' usando o StandardScaler e armazenando os valores normalizados em uma nova coluna 'date_time_normalized'.\n",
    "\n",
    "# # Normalizar a coluna \"date_time\"\n",
    "# scaler = StandardScaler()\n",
    "# df['date_time_normalized'] = scaler.fit_transform(df[['DateTime']])\n",
    "# df = df.drop('DateTime', axis=1)\n",
    "\n",
    "# new_df = df.drop('target_column1', axis=1) \n",
    "# new_df = df.drop('target_column2', axis=1)\n",
    "# new_df = df.drop('target_column3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('target_column', axis=1)\n",
    "y = df['target_column']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "trainer = LMSTrainer()\n",
    "num_columns = X.shape[1] + 1\n",
    "print(num_columns)\n",
    "theta = [0] * num_columns \n",
    "theta[0] = 3\n",
    "predictor = trainer.fit(X_train.values, theta, y_train.values)\n",
    "predictor.predict(X_test.values, theta, y_train.values)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(eixo_Y, eixo_X, marker='o', linestyle='-')\n",
    "plt.title('Convergência da Função de Custo')\n",
    "plt.xlabel('Número de Iterações')\n",
    "plt.ylabel('Valor da Função de Custo')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # 10 50 30 90 40 100\n",
    "# x = [[156,2,2,2,2,4.3],\n",
    "#      [135,3,2,2,1,3.4],\n",
    "#      [65,1,1,1,1,4.8],\n",
    "#      [100,2,2,1,2,4.2],\n",
    "#      [110,2,2,2,1,3.9],\n",
    "#      [75,2,1,2,2,4.6],\n",
    "#      [55,1,1,1,1,4.4]]\n",
    "\n",
    "# y = [2417,2130,1345,1784,1840,1610,1235]\n",
    "# # theta = [10,50,30,90,40,100]\n",
    "# theta = [0,0,0,0,0,0,0]\n",
    "\n",
    "# x2 = [[54,1,1,2,4,2.0],\n",
    "#       [455,8,9,20,5,5],\n",
    "#       [10,1,0,0,0,1],\n",
    "#       [101,2,4,1,1,3],\n",
    "#       [70,2,4,0,0,2.3],\n",
    "#       [47,2,1,1,1,4],\n",
    "#       [87,3,2,2,2,4.5]]\n",
    "\n",
    "# trainer = LMSTrainer()\n",
    "# predictor = trainer.fit(x,theta,y)\n",
    "\n",
    "# teste = [0] * len(y)\n",
    "# for i in range(len(x)):\n",
    "#     teste[i] = h(x, i, theta)\n",
    "    \n",
    "# print(teste, theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
